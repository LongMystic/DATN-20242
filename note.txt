- connect hive to spark thrift:
    !connect jdbc:hive2://spark-thriftserver:10000

- at start hadoop:
    run some cmd:
        $ $HADOOP_HOME/bin/hadoop fs -mkdir       /tmp
        $ $HADOOP_HOME/bin/hadoop fs -mkdir       /user/hive/warehouse
        $ $HADOOP_HOME/bin/hadoop fs -chmod g+w   /tmp
        $ $HADOOP_HOME/bin/hadoop fs -chmod g+w   /user/hive/warehouse

beeline -u "jdbc:hive2://spark-thriftserver:10000" -n spark_user

CREATE TABLE iceberg.default.long_test (
  id INT,
  name STRING
)
using iceberg

Apache Spark SQL	pip install pyhive	hive://hive@{hostname}:{port}/{database}

ALTER DATABASE test CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
use test;
ALTER TABLE category CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;